{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - Data collection and description\n",
    "The second task is to intimately acquaint yourself with the data, preprocess it and complete all the necessary descriptive statistics tasks. We expect you to have a pipeline in place, fully documented in a notebook, and show us that youâ€™ve advanced with your understanding of the project goals by updating its README description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .setMaster('local[*]')\\\n",
    "    .set('spark.executor.memory', '2g')\\\n",
    "    .set('spark.driver.memory', '2g')\\\n",
    "    .set('spark.executor.instances', '4')\n",
    "    \n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gaining insight into the Amazon product network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon dataset contains relations among products, such as \"also viewed\", \"also bought\", \"bought together\", \"bought after viewing\". These links can be used to create a graph that represents products with similar characteristics, that is, products that are viewed together but not bought together.\n",
    "Our idea is to exploit the dataset in order to create clusters of competing products. These clusters may be used not only to identify the best product in terms of rating and sales within a group, but also to investigate how brands can influence the sales and the prices of similar products.\n",
    "\n",
    "The dataset is transformed into a graph of relations between products, where the vertices represent products, and edges represent competition between products. For instance, if two products are viewed together (people who viewed product A also viewed product B, and vice versa) but not bought together, they are competitors. On the other hand, two products that are viewed together and bought together are not competitors (e.g. a user buys a smartphone and a cover). A way of expressing this in more formal terms is with max-cliques, that is, finding sets of vertices that are totally interconnected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show** \n",
    "- That you can handle the data in its size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon dataset consists of two JSON files: \n",
    "- *metadata.json*: contains information about the products, such as their unique ID, description and price. The size of the dataset is 9.81 GB (uncompressed, in JSON format).\n",
    "- *reviews.json*: contains reviews and ratings associated with each product, as well as the helpfulness of each review. The size of the dataset is approximately 100 GB (again, uncompressed and in JSON format).\n",
    "\n",
    "Since the dataset does not fit in memory, we cannot process it using libraries such as Pandas, unless we reduce its size first.\n",
    "Therefore, the initial data processing was carried out using **PySpark**, both on the cluster (especially for the reviews dataset) and in local. While it may seem inappropriate at first, using Spark in local makes sense for medium-sized datasets (like the metadata one), as it automatically parallelizes jobs using all cores, and spills to disk intermediate results that cannot fit in main memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "The dataset contains a list of entries of products with the following fields (some of them may be missing):\n",
    "- **asin**: unique ID of the product.\n",
    "- **title**: name of the product.\n",
    "- **price**: price in US dollars.\n",
    "- **imUrl**: URL of the product image.\n",
    "- **related**: related products, which contains the sub-lists: *also bought, also viewed, bought together, buy after viewing*.\n",
    "- **salesRank**: sales rank information, i.e. how well the product compares to other products in the same category in terms of sales.\n",
    "- **brand**: brand name.\n",
    "- **categories**: the category(-ies) to which the product belongs.\n",
    "\n",
    "These fields are already sufficient for building our graph, since they contain the above-mentioned relations between products, as well as their IDs and names. Here we present an example of such a record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asin': '0000143561',\n",
       "  'categories': [['Movies & TV', 'Movies']],\n",
       "  'description': '3Pack DVD set - Italian Classics, Parties and Holidays.',\n",
       "  'imUrl': 'http://g-ecx.images-amazon.com/images/G/01/x-site/icons/no-img-sm._CB192198896_.gif',\n",
       "  'price': 12.99,\n",
       "  'related': {'also_viewed': ['B0036FO6SI',\n",
       "    'B000KL8ODE',\n",
       "    '000014357X',\n",
       "    'B0037718RC',\n",
       "    'B002I5GNVU',\n",
       "    'B000RBU4BM'],\n",
       "   'buy_after_viewing': ['B0036FO6SI',\n",
       "    'B000KL8ODE',\n",
       "    '000014357X',\n",
       "    'B0037718RC']},\n",
       "  'salesRank': {'Movies & TV': 376041},\n",
       "  'title': 'Everyday Italian (with Giada de Laurentiis), Volume 1 (3 Pack): Italian Classics, Parties, Holidays'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('data/metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'price' in x and 'related' in x)\\\n",
    "    .take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we had to use `ast.literal_eval` instead of the JSON library because the dataset is not in standard JSON format. It appears to be in Python's `print() ` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, we have to decide whether it makes sense to carry out our analysis on the whole dataset, or if it is more appropriate to select only a subset of all categories. It turns out that the latter is the case: sales in categories such as **Music**, **Books**, or **Clothes** depend on people's personal preferences, and are less (if not at all) prone to competition. On the contrary, electronic products are the ones that are subject to real competition, as clients wants to get the best possible product at the lowest cost. Moreover, this selection step allows us to reduce the size of the dataset and process it more efficiently.\n",
    "\n",
    "Therefore, the first step consists in listing all categories and selecting those in which we are interested. As can be seen from the example above, categories are represented as hierarchies, e.g. `[\"Sports & Outdoors\", \"Other Sports\", \"Dance\"]` means that the product can be found in the category **Sports & Outdoors -> Other Sports -> Dance**. Firstly, we extract the list of macro-categories (top-level categories such as **Sports & Outdoors**) along with their product count, and we inspect them manually. Our goal is to choose macro-categories containing products that can be objectively compared in terms of features and characteristics, such as *Electronics* or *Cell phones*. Converseley, categories of which the purchase decision is subjective (e.g. clothes and books) are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all top-level categories along with their product count\n",
    "categories_macro = sc.textFile('data/metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'categories' in x)\\\n",
    "    .flatMap(lambda x: x['categories'])\\\n",
    "    .map(lambda x: x[0])\\\n",
    "    .map(lambda x: (x, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Clothing, Shoes &amp; Jewelry</td>\n",
       "      <td>3429257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Books</td>\n",
       "      <td>2855617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CDs &amp; Vinyl</td>\n",
       "      <td>1523001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Kindle Store</td>\n",
       "      <td>1088341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>543514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>437019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "      <td>357693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toys &amp; Games</td>\n",
       "      <td>336460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>331484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Digital Music</td>\n",
       "      <td>281157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Tools &amp; Home Improvement</td>\n",
       "      <td>269149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "      <td>263163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>259227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>208912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>194914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Grocery &amp; Gourmet Food</td>\n",
       "      <td>171760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Office Products</td>\n",
       "      <td>135024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Arts, Crafts &amp; Sewing</td>\n",
       "      <td>117466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>110757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patio, Lawn &amp; Garden</td>\n",
       "      <td>109117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>85474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Video Games</td>\n",
       "      <td>74342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Baby</td>\n",
       "      <td>71317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Apps for Android</td>\n",
       "      <td>61619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Industrial &amp; Scientific</td>\n",
       "      <td>47279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon Instant Video</td>\n",
       "      <td>30648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Software</td>\n",
       "      <td>25804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon Fashion</td>\n",
       "      <td>24145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Appliances</td>\n",
       "      <td>11656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category    count\n",
       "49  Clothing, Shoes & Jewelry  3429257\n",
       "13                      Books  2855617\n",
       "66                CDs & Vinyl  1523001\n",
       "30               Kindle Store  1088341\n",
       "72          Sports & Outdoors   543514\n",
       "73                Electronics   500600\n",
       "52             Home & Kitchen   437019\n",
       "32  Cell Phones & Accessories   357693\n",
       "36               Toys & Games   336460\n",
       "9                  Automotive   331484\n",
       "35              Digital Music   281157\n",
       "47   Tools & Home Improvement   269149\n",
       "50     Health & Personal Care   263163\n",
       "71                     Beauty   259227\n",
       "70                Movies & TV   208912\n",
       "0                               194914\n",
       "10     Grocery & Gourmet Food   171760\n",
       "65            Office Products   135024\n",
       "48      Arts, Crafts & Sewing   117466\n",
       "44               Pet Supplies   110757\n",
       "3        Patio, Lawn & Garden   109117\n",
       "78        Musical Instruments    85474\n",
       "19                Video Games    74342\n",
       "64                       Baby    71317\n",
       "42           Apps for Android    61619\n",
       "79    Industrial & Scientific    47279\n",
       "4        Amazon Instant Video    30648\n",
       "82                   Software    25804\n",
       "11             Amazon Fashion    24145\n",
       "69                 Appliances    11656"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We show the top categories sorted by product count\n",
    "df = pd.DataFrame(categories_macro)\n",
    "df.columns = ['category', 'count']\n",
    "df.sort_values('count', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our consideration, we have decided to include the following macro categories in our analysis: **Electronics**, **Cell Phones & Accessories**, **Automotive**, **Tools & Home Improvement**, and **Musical Instruments**. The choice is motivated both by their sizes and by the fact that they represent products that are comparable.\n",
    "\n",
    "Now, we want to have a more detailed description of the categories. Therefore, for each macro-category, we convert the category lists within each product to a tree. We do this in a distributed way, using Spark. The job works as follows:\n",
    "- **Map phase:** each list is converted to a tree. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforms a category list into a flat tree (a tree with a linked list topology)\n",
    "def convert_to_tree(elements):\n",
    "    root = {}\n",
    "    node = root\n",
    "    for element in elements:\n",
    "        node[element] = (1, {}) # Tuple: (product count, children)\n",
    "        node = node[element][1]\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sports & Outdoors': (1, {'Other Sports': (1, {'Dance': (1, {})})})}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_tree([\"Sports & Outdoors\", \"Other Sports\", \"Dance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each category includes the product count along with its subcategories (children). The product count within a category includes the sum of the product counts of all its children.\n",
    "\n",
    "- **Reduce phase:** all trees are merged together recursively, creating a huge category tree that reflects the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge nodes\n",
    "def merge_trees(a, b):\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            a[key] = (a[key][0] + b[key][0], a[key][1])\n",
    "            merge_trees(a[key][1], b[key][1])\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sports & Outdoors': (2,\n",
       "  {'Other Sports': (1, {'Dance': (1, {})}), 'Supplies': (1, {})})}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = convert_to_tree([\"Sports & Outdoors\", \"Other Sports\", \"Dance\"])\n",
    "b = convert_to_tree([\"Sports & Outdoors\", \"Supplies\"])\n",
    "merge_trees(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the actual job on Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the category tree\n",
    "category_tree = sc.textFile('data/metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'categories' in x)\\\n",
    "    .flatMap(lambda x: x['categories'])\\\n",
    "    .map(convert_to_tree)\\\n",
    "    .reduce(merge_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, the subtree of *Cell Phones & Accessories* is shown, with product count for each sub category. As can be seen, sub categories may differ significantly in terms of belonging products. Therefore, some heuristics may be necessary to group categories that contains a small number of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357693,\n",
       " {'Accessories': (109763,\n",
       "   {'Accessory Kits': (26545, {}),\n",
       "    'Audio Adapters': (497, {}),\n",
       "    'Batteries': (9882,\n",
       "     {'Battery Charger Cases': (560, {}),\n",
       "      'External Battery Packs': (2079, {}),\n",
       "      'Internal Batteries': (6651, {})}),\n",
       "    'Bluetooth Speakers': (782, {}),\n",
       "    'Car Accessories': (5863,\n",
       "     {'Car Cradles & Mounts': (4705,\n",
       "       {'Car Cradles': (424, {}), 'Car Mounts': (4189, {})}),\n",
       "      'Car Kits': (845, {}),\n",
       "      'Car Speakerphones': (312, {})}),\n",
       "    'Chargers': (17463,\n",
       "     {'Car Chargers': (7650, {}),\n",
       "      'Cell Phone Docks': (1894, {}),\n",
       "      'International Chargers': (169, {}),\n",
       "      'Solar Chargers': (284, {}),\n",
       "      'Travel Chargers': (7122, {})}),\n",
       "    'Cradles, Mounts & Stands': (48, {'Stands': (47, {})}),\n",
       "    'Data Cables': (6671, {}),\n",
       "    'Headsets': (10197,\n",
       "     {'Bluetooth Headsets': (5066, {}), 'Wired Headsets': (5023, {})}),\n",
       "    'Phone Charms': (3073, {}),\n",
       "    'Replacement Parts': (6592, {}),\n",
       "    'SIM Cards & Tools': (506, {}),\n",
       "    'Screen Protectors': (15879, {}),\n",
       "    'Signal Boosters': (586, {}),\n",
       "    'Smart Watches & Accessories': (148, {}),\n",
       "    'Stylus Pens': (3584, {})}),\n",
       "  'Cases': (239587,\n",
       "   {'Armbands': (1541, {}),\n",
       "    'Basic Cases': (223962, {}),\n",
       "    'Customizable Cases': (2, {}),\n",
       "    'Holsters & Clips': (4352, {}),\n",
       "    'Sleeves': (184, {}),\n",
       "    'Wallet Cases': (7777, {}),\n",
       "    'Waterproof Cases': (1757, {})}),\n",
       "  'Cell Phones': (7757,\n",
       "   {'Contract Cell Phones': (619, {}),\n",
       "    'No-Contract Cell Phones': (767,\n",
       "     {'Minutes': (52, {}), 'Phones': (713, {})}),\n",
       "    'Unlocked Cell Phones': (6328, {})}),\n",
       "  'Connected Devices': (63,\n",
       "   {'Mobile Broadband': (53,\n",
       "     {'Data Cards': (1, {}),\n",
       "      'Mobile Hotspots': (34, {}),\n",
       "      'USB Modems': (10, {})}),\n",
       "    'Tablets': (9, {})})})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each node represents a (count, children) tuple\n",
    "category_tree['Cell Phones & Accessories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews dataset (`reviews.json`) has a size of approximately 100 GB. Each review contains the following fields:\n",
    "- **reviewerID**: unique ID associated to each user.\n",
    "- **asin**: unique ID associated to each product.\n",
    "- **reviewerName**: name of the user.\n",
    "- **helpful**: helpfulness rating of the review (tuple of 2 elements: # helpful and # not helpful).\n",
    "- **reviewText**: text of the review.\n",
    "- **overall**: rating of the product from 1 to 5 stars.\n",
    "- **summary** - summary of the review.\n",
    "- **unixReviewTime** - unix timestamp of the review.\n",
    "- **reviewTime** - raw timestamp of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our project is mainly focused on products, we are not interested in individual reviews. However, we still need this dataset in order to compute the aggregate ratings for each product and merge them into our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show **\n",
    "- That you considered ways to enrich, filter, transform the data according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the Amazon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large size of the Amazon dataset, we decided to create a custom dataset prior to performing any further analysis. The custom dataset, which has been named *reduced*, contains only products belonging to the macro-categories selected in the previous parapraph. To further reduce the size, every image URL associated to a product is deleted. In addition, the review ratings of each product are averaged and merged with the products. As a result, we obtain a smaller *metadata* dataset (1.71 GB) that is enriched with the average product rating field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregate ratings\n",
    "The average product rating is computed from the data in the *reviews* dataset. For each entry, the product ID and the rating are stored, respectively, in the *asin* and *overall* fields. To compute the rating, entries are grouped by product ID and then \n",
    "averaged on the *overall* field. In addition to the average rating for each product, we add some additional information which might come handy later: the number of reviews (`num_reviews`), and the ratio of helpful reviews (`helpful_fraction`), defined as **# helpful / (# helpful + # not helpful)**.\n",
    "The output is saved in JSON format as `aggregate_ratings.json`. The code for processing the data (shown below) was executed on the ADA cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "import json\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd = sc.textFile('/datasets/productGraph/complete.json')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .map(lambda x: (x['asin'], x['overall'], x['helpful'][0], x['helpful'][1]))\n",
    "\n",
    "sqlContext.createDataFrame(rdd, ['asin', 'overall', 'helpful', 'not_helpful'])\\\n",
    "    .groupBy('asin')\\\n",
    "    .agg(\n",
    "        func.mean('overall').alias('average_rating'),\n",
    "        func.count('overall').alias('num_reviews'),\n",
    "        (func.sum('helpful') / (func.sum('helpful') + func.sum('not_helpful'))).alias('helpful_fraction')\n",
    "    )\\\n",
    "    .toJSON()\\\n",
    "    .saveAsTextFile('aggregate_ratings.json')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the datasets\n",
    "*Metadata* is filtered so as to mantain only the products belonging to the macro categories of interest, which are then merged with *aggregate_ratings*. The code that generates the *reduced* dataset is shown below.\n",
    "\n",
    "TODO: write about multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The list of macro categories that we want to extract\n",
    "categories_to_extract = set(['Electronics', 'Cell Phones & Accessories', 'Automotive',\\\n",
    "                             'Tools & Home Improvement', 'Musical Instruments'])\n",
    "\n",
    "# Extract macro category and delete img url to reduce size\n",
    "def extract_category(x):\n",
    "    x['category'] = x['categories'][0]\n",
    "    del x['categories']\n",
    "    x['num_reviews'] = 0 # The number of reviews is 0 in the default case\n",
    "    if 'imUrl' in x:\n",
    "        del x['imUrl']\n",
    "    return x\n",
    "\n",
    "# Load the aggregate ratings\n",
    "ratings = sc.textFile('data/aggregate_ratings.json')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .map(lambda x: (x['asin'], x))\n",
    "\n",
    "# Filter products and merge datasets.\n",
    "# Note that we use the left outer join, so as to include products that have no reviews.\n",
    "sc.textFile('data/metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'categories' in x)\\\n",
    "    .map(extract_category)\\\n",
    "    .filter(lambda x: x['category'][0] in categories_to_extract)\\\n",
    "    .map(lambda x: (x['asin'], x))\\\n",
    "    .leftOuterJoin(ratings)\\\n",
    "    .map(lambda x: x[1])\\\n",
    "    .map(lambda x: x[0] if x[1] == None else {**x[0], **x[1]})\\\n",
    "    .map(lambda x: json.dumps(x))\\\n",
    "    .saveAsTextFile('data/reduced.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a light sandbox dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform tests on data rapidly, we have decided to further reduce the Amazon dataset. Specifically, from *reduced* we built a lighter dataset containg only a single macro category, being *Musical Instruments*. The code that generates the dataset and the category tree are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.textFile('reduced.json')\\\n",
    "    .filter(lambda x: json.loads(x)['category'][0] == 'Musical Instruments')\\\n",
    "    .coalesce(1)\\\n",
    "    .saveAsTextFile('musical_instruments.json')\n",
    "\n",
    "category_tree['Musical Instruments'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show**\n",
    "- That you understand whatâ€™s into the data (formats, distributions, missing values, correlations, etc.).\n",
    "- That you have updated your plan in a reasonable way, reflecting your improved knowledge after data acquaintance. In particular, discuss how your data suits your project needs and discuss the methods youâ€™re going to use, giving their essential mathematical details in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@todo**\n",
    "- show some correlation between the variables\n",
    "- show some cliques and infer some conclusion. are the clicques well constructed? can we claim that  a product is better than the others within the clique? if yes, with what metrics? (analyze correlations)\n",
    "- Are the cliques meaningful? We have seen that some cliques are composed of the same object with different colors, or even of the same exact products from different vendors. It may be necessary to add some considerations on how dealing with these extreme cases.\n",
    "- How do we merge cliques? What heuristic do we choose? How do we deal with single-product-size cliques?\n",
    "- **Build histogram of missing features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation analysis\n",
    "We performed some analyses on the *musical_instruments* dataset variables. In details, we investigated the correlations among price, review rating and sale rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ratings = sc.textFile('musical_instruments.json')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .filter(lambda x: x['num_reviews'] > 10 and 'price' in x and 'salesRank' in x and 'Musical Instruments' in x['salesRank'])\\\n",
    "    .map(lambda x: (x['price'], x['average_rating'], x['salesRank']['Musical Instruments']))\\\n",
    "    .collect()\n",
    "    \n",
    "df = pd.DataFrame(all_ratings)\n",
    "print(len(df))\n",
    "df.columns = ['price', 'rating', 'rank']\n",
    "corr = df.corr()\n",
    "display(df.head())\n",
    "plt.figure(figsize=(10,10))\n",
    "_ = sns.heatmap(corr, annot=True,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the graphs above, we discuss the following outcomes on the analysis of musical instruments:\n",
    "- As the price increases, the ratings tend to have lower variance and higher mean. In other words, more expensive products have on average higher ratings, and are less likely to be not popular. \n",
    "- As the price increases, the variance of sale rate tends to be lower. Thefore, the sales are less likely to be low.\n",
    "- As the sale rank decreases, ratings tend do be higher and less distributed over the range.\n",
    "\n",
    "**@todo**: However, these analysis may vary among different categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show **\n",
    "- That your plan for analysis and communication is now reasonable and sound, potentially discussing alternatives to your choices that you considered but dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@todo**\n",
    "- discuss the feasability of the project\n",
    "- define some further internal steps before milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder: Internal steps before milestone2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the rules for creating the graph (i.e. the influence of each relation type).\n",
    "- Devise an efficient algorithm for extracting cliques or highly connected subgraphs, and, possibly, merging them into clusters.\n",
    "- Find useful insights into the structure of these clusters, apart from obvious ones (the best product in a cluster). For example:\n",
    "-- Do people always choose the most cheap product among related products?\n",
    "-- Conversely, does the best product cost more than the others?\n",
    "-- Are the best products sold only by well-known brands?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

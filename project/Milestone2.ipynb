{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 - Data collection and description\n",
    "The second task is to intimately acquaint yourself with the data, preprocess it and complete all the necessary descriptive statistics tasks. We expect you to have a pipeline in place, fully documented in a notebook, and show us that you’ve advanced with your understanding of the project goals by updating its README description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gaining insights into the Amazon product network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon dataset contains relations among products, such as \"also viewed\", \"also bought\", \"bought together\", \"bought after viewing\". These links can be used to create a graph that represents products with similar characteristics, that is, products that are viewed together but not bought together.\n",
    "Our idea is to exploit the dataset to create clusters of competing products. These clusters may be used not only to identify the best product in terms of rate and sale within a group, but also to investigate how brands can influence the sale and the price of similar products.\n",
    "\n",
    "The dataset will be transformed into a graph of relations between products, where the vertices represent products, and edges represent competitions between products. For instance, if two products are viewed together (people who viewed product A also viewed product B, and vice versa) but not bought together, they are competitors. On the other hand, two products that are viewed together and bought together are not competitors (e.g. a user buys a smartphone and a cover). A way of expressing this in more formal terms is with max-cliques, that is, finding sets of vertices that are totally interconnected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show** \n",
    "- That you can handle the data in its size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Amazon dataset consists of two JSON files: \n",
    "- *metadata.json*: contains information about the products, such as their unique ID, description and price. The size of the dataset is 9.81 GB.\n",
    "- *reviews.json*: contains reviews and ratings associated to each product. The size of the dataset is approximately 100 GB.\n",
    "\n",
    "To handle the files and use them on our local machines, we have decided to install and use *PySpark*. However, also the cluster is necessary to process the reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "The dataset contains a list of entries of products with the following fields (some may be missing):\n",
    "- **asin**: unique ID of the product.\n",
    "- **title**: name of the product.\n",
    "- **price**: price in US dollars.\n",
    "- **imUrl**: url of the product image.\n",
    "- **related**: related products, which contains the sub-lists: *also bought, also viewed, bought together, buy after viewing*.\n",
    "- **salesRank**: sales rank information, i.e. how many times the product has been sold over the total number of sold products in the category.\n",
    "- **brand**: brand name.\n",
    "- **categories**: list to which categories the products belong.\n",
    "\n",
    "These fields are already sufficient to build our graph, since they contain the above-mentioned relations between products, as well as their IDs and names. <br>\n",
    "Due to the large number of products in the dataset, we decided to process those within a small set of categories. The *categories* field contains a list that represents the hierarchy of categories to which the product has been assigned, i.e. the first element of the list is the macro category, and the last element is the smallest sub category.\n",
    "We collected all the macro categories, of which number is relatively high, and inspected what categories might be suitable for our project. <br>\n",
    "Firstly, we performed a qualitative inspection, choosing macro categories containing products that can be objectively compared in terms of features and characteristics, such as *Electronics* or *Cell phones*. On the other hand, categories of products of which the purchase decision is subjective (e.g. clothes and books) have been discarded. <br>\n",
    "Secondly, we have counted the number of products associated to each macro category, and selected categories with a relatively large number of products.\n",
    "According to our analysis, we have decided to process the following macro categories: *Electronics, Cell Phones & Accessories, Automotive, Tools & Home Improvement, Musical Instruments*. <br>\n",
    "**@todo(improve algo description)** For each macro category, we built a tree of sub categories. Each category is translated into the node of a tree. Each node contains its children and its cumulative number of products, both of the children and itself. Nodes are then merged together recursevely to construct larger trees. The code of the algorithm is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforms an element into a node\n",
    "def convert_to_trie(elements):\n",
    "    root = {}\n",
    "    node = root\n",
    "    for element in elements:\n",
    "        node[element] = ({}, 1)\n",
    "        node = node[element][0]\n",
    "    return root\n",
    "\n",
    "# Merge nodes\n",
    "def merge_tries(a, b):\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            a[key] = (a[key][0], a[key][1] + b[key][1])\n",
    "            merge_tries(a[key][0], b[key][0])\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "\n",
    "# Build the category tree\n",
    "category_tree = sc.textFile(r'C:\\Spinn3r\\amazon\\metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'categories' in x)\\\n",
    "    .flatMap(lambda x: x['categories'])\\\n",
    "    .map(convert_to_trie)\\\n",
    "    .reduce(merge_tries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, the tree of *Cell Phones & Accessories* is showed, with product count for each sub category. As can be seen, sub categories may differ significantly in terms of belonging products. Therefore, some heuristics may be necessary to group categories that contains a small number of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_tree['Cell Phones & Accessories'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{'Accessories': ({'Accessory Kits': ({}, 26545),\n",
    "   'Audio Adapters': ({}, 497),\n",
    "   'Batteries': ({'Battery Charger Cases': ({}, 555),\n",
    "     'External Battery Packs': ({}, 2053),\n",
    "     'Internal Batteries': ({}, 6645)},\n",
    "    9842),\n",
    "   'Bluetooth Speakers': ({}, 779),\n",
    "   'Car Accessories': ({'Car Cradles & Mounts': ({'Car Cradles': ({}, 424),\n",
    "       'Car Mounts': ({}, 4183)},\n",
    "      4699),\n",
    "     'Car Kits': ({}, 841),\n",
    "     'Car Speakerphones': ({}, 297)},\n",
    "    5837),\n",
    "   'Chargers': ({'Car Chargers': ({}, 7623),\n",
    "     'Cell Phone Docks': ({}, 1886),\n",
    "     'International Chargers': ({}, 161),\n",
    "     'Solar Chargers': ({}, 275),\n",
    "     'Travel Chargers': ({}, 6845)},\n",
    "    17111),\n",
    "   'Cradles, Mounts & Stands': ({'Stands': ({}, 44)}, 44),\n",
    "   'Data Cables': ({}, 6647),\n",
    "   'Headsets': ({'Bluetooth Headsets': ({}, 5033),\n",
    "     'Wired Headsets': ({}, 5015)},\n",
    "    10148),\n",
    "   'Phone Charms': ({}, 3073),\n",
    "   'Replacement Parts': ({}, 6583),\n",
    "   'SIM Cards & Tools': ({}, 506),\n",
    "   'Screen Protectors': ({}, 15865),\n",
    "   'Signal Boosters': ({}, 586),\n",
    "   'Smart Watches & Accessories': ({}, 147),\n",
    "   'Stylus Pens': ({}, 3581)},\n",
    "  109235),\n",
    " 'Cases': ({'Armbands': ({}, 1521),\n",
    "   'Basic Cases': ({}, 222345),\n",
    "   'Customizable Cases': ({}, 2),\n",
    "   'Holsters & Clips': ({}, 4224),\n",
    "   'Sleeves': ({}, 21),\n",
    "   'Wallet Cases': ({}, 954),\n",
    "   'Waterproof Cases': ({}, 133)},\n",
    "  229207),\n",
    " 'Cell Phones': ({'Contract Cell Phones': ({}, 618),\n",
    "   'No-Contract Cell Phones': ({'Minutes': ({}, 52), 'Phones': ({}, 697)},\n",
    "    750),\n",
    "   'Unlocked Cell Phones': ({}, 6287)},\n",
    "  7693),\n",
    " 'Connected Devices': ({'Mobile Broadband': ({'Data Cards': ({}, 1),\n",
    "     'Mobile Hotspots': ({}, 34),\n",
    "     'USB Modems': ({}, 9)},\n",
    "    52),\n",
    "   'Tablets': ({}, 9)},\n",
    "  62)}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a list of entries of reviews with the following fields:\n",
    "- **reviewerID**: unique ID associated to each user.\n",
    "- **asin**: unique ID associated to each product.\n",
    "- **reviewerName**: name of the user.\n",
    "- **helpful**: helpfulness rating of the review.\n",
    "- **reviewText**: text of the review.\n",
    "- **overall**: rating of the product.\n",
    "- **summary** - summary of the review\n",
    "- **unixReviewTime** - unix timestamp of the review.\n",
    "- **reviewTime** - raw timestap of the review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being our project mainly focused on products, we consider these fields less relevant. However, the *overall* field could be exploited to infer additional information, i.e. the average rating could show the quality of a product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show **\n",
    "- That you considered ways to enrich, filter, transform the data according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the Amazon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large size of the Amazon dataset, we decided to create a custom dataset prior to performing any further analysis. The custom dataset, which has been named *reduced*, contains only products belonging to the macro categories extracted in the previous parapraph. To further reduce the size, every image URL associated to a product has been deleted. In addition, the review ratings of each product are averaged and merged with the products. As a result, we obtain a smaller *metadata* dataset (1.71 GB) that is enriched with the average product rating field. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregate ratings\n",
    "The average product rating is computed from the data in the *reviews* dataset. For each entry, the product ID and the rating are stored, respectively, in the *asin* and *overall* fields. To compute the rating, entries are grouped by product ID and then \n",
    "averaged on the *overall* field. <br>\n",
    "The average product ratings are stored in the *aggregate_ratings* dataset. The code of the processing is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.textFile(r'C:\\Spinn3r\\amazon\\reviews_sample.json.gz')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .map(lambda x: (x['asin'], x['overall'], x['helpful'][0], x['helpful'][1]))\\\n",
    "    .toDF(['asin', 'overall', 'helpful', 'not_helpful'])\\\n",
    "    .groupBy('asin')\\\n",
    "    .agg(\n",
    "        func.mean('overall').alias('average_rating'),\n",
    "        func.count('overall').alias('num_reviews'),\n",
    "        (func.sum('helpful') / func.sum('not_helpful')).alias('helpful_fraction')\n",
    "    )\\\n",
    "    .toJSON()\\\n",
    "    .coalesce(1)\\\n",
    "    .saveAsTextFile('aggregate_ratings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the datasets\n",
    "*Metadata* is filtered to mantain only the products belonging to the macro categories of interest, which are then merged with *aggregate_ratings*. The code that generates the *reduced* dataset is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The list of macro categories that we want to extract\n",
    "categories_to_extract = set(['Electronics', 'Cell Phones & Accessories', 'Automotive', 'Tools & Home Improvement', 'Musical Instruments'])\n",
    "\n",
    "# Extract macro category and delete img url to reduce size\n",
    "def extract_category(x):\n",
    "    x['category'] = x['categories'][0]\n",
    "    del x['categories']\n",
    "    x['num_reviews'] = 0\n",
    "    if 'imUrl' in x:\n",
    "        del x['imUrl']\n",
    "    return x\n",
    "\n",
    "# Load the aggregate ratings\n",
    "ratings = sc.textFile(r'C:\\Spinn3r\\amazon\\aggregate_ratings.json')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .map(lambda x: (x['asin'], x))\n",
    "\n",
    "# Filter products and merge datasets\n",
    "sc.textFile(r'C:\\Spinn3r\\amazon\\metadata.json')\\\n",
    "    .map(lambda x: ast.literal_eval(x))\\\n",
    "    .filter(lambda x: 'categories' in x)\\\n",
    "    .map(extract_category)\\\n",
    "    .filter(lambda x: x['category'][0] in categories_to_extract)\\\n",
    "    .map(lambda x: (x['asin'], x))\\\n",
    "    .leftOuterJoin(ratings)\\\n",
    "    .map(lambda x: x[1])\\\n",
    "    .map(lambda x: x[0] if x[1] == None else {**x[0], **x[1]})\\\n",
    "    .map(lambda x: json.dumps(x))\\\n",
    "    .saveAsTextFile('reduced.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a light sandbox dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform tests on data rapidly, we have decided to further reduce the Amazon dataset. Specifically, from *reduced* we built a lighter dataset containg only a single macro category, being *Musical Instruments*. The code that generates the dataset and the category tree are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.textFile('reduced.json')\\\n",
    "    .filter(lambda x: json.loads(x)['category'][0] == 'Musical Instruments')\\\n",
    "    .coalesce(1)\\\n",
    "    .saveAsTextFile('musical_instruments.json')\n",
    "\n",
    "category_tree['Musical Instruments'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show**\n",
    "- That you understand what’s into the data (formats, distributions, missing values, correlations, etc.).\n",
    "- That you have updated your plan in a reasonable way, reflecting your improved knowledge after data acquaintance. In particular, discuss how your data suits your project needs and discuss the methods you’re going to use, giving their essential mathematical details in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@todo**\n",
    "- show some correlation between the variables\n",
    "- show some cliques and infer some conclusion. are the clicques well constructed? can we claim that  a product is better than the others within the clique? if yes, with what metrics? (analyze correlations)\n",
    "- Are the cliques meaningful? We have seen that some cliques are composed of the same object with different colors, or even of the same exact products from different vendors. It may be necessary to add some considerations on how dealing with these extreme cases.\n",
    "- How do we merge cliques? What heuristic do we choose? How do we deal with single-product-size cliques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation analysis\n",
    "We performed some analyses on the *musical_instruments* dataset variables. In details, we investigated the correlations among price, review rating and sale rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ratings = sc.textFile('musical_instruments.json')\\\n",
    "    .map(lambda x: json.loads(x))\\\n",
    "    .filter(lambda x: x['num_reviews'] > 10 and 'price' in x and 'salesRank' in x and 'Musical Instruments' in x['salesRank'])\\\n",
    "    .map(lambda x: (x['price'], x['average_rating'], x['salesRank']['Musical Instruments']))\\\n",
    "    .collect()\n",
    "    \n",
    "df = pd.DataFrame(all_ratings)\n",
    "print(len(df))\n",
    "df.columns = ['price', 'rating', 'rank']\n",
    "corr = df.corr()\n",
    "display(df.head())\n",
    "plt.figure(figsize=(10,10))\n",
    "_ = sns.heatmap(corr, annot=True,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the graphs above, we discuss the following outcomes on the analysis of musical instruments:\n",
    "- As the price increases, the ratings tend to have lower variance and higher mean. In other words, more expensive products have on average higher ratings, and are less likely to be not popular. \n",
    "- As the price increases, the variance of sale rate tends to be lower. Thefore, the sales are less likely to be low.\n",
    "- As the sale rank decreases, ratings tend do be higher and less distributed over the range.\n",
    "\n",
    "**@todo**: However, these analysis may vary among different categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@show **\n",
    "- That your plan for analysis and communication is now reasonable and sound, potentially discussing alternatives to your choices that you considered but dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**@todo**\n",
    "- discuss the feasability of the project\n",
    "- define some further internal steps before milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder: Internal steps before milestone2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the rules for creating the graph (i.e. the influence of each relation type).\n",
    "- Devise an efficient algorithm for extracting cliques or highly connected subgraphs, and, possibly, merging them into clusters.\n",
    "- Find useful insights into the structure of these clusters, apart from obvious ones (the best product in a cluster). For example:\n",
    "-- Do people always choose the most cheap product among related products?\n",
    "-- Conversely, does the best product cost more than the others?\n",
    "-- Are the best products sold only by well-known brands?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
